<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
<style>
        :root {
            --color-beige: #f5eddc;
            --color-dark-beige: #e8dcc8;
            --color-black: #1a1a1a;
            --color-orange: #E86A33;
            --color-light-orange: #FF8C5A;
            --color-white: #FFFFFF;
            --color-text-light: #4a5568;
            --color-text-dark: #2d3748;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Inter', 'Segoe UI', system-ui, -apple-system, BlinkMacSystemFont, sans-serif;
        }

        body {
            color: var(--color-black);
            line-height: 1.6;
            overflow-x: hidden;
            background: var(--color-beige);
        }

        /* Header */
        .header {
            position: fixed;
            top: 0;
            width: 100%;
            background: rgba(26, 26, 26, 0.97);
            padding: 20px 0;
            z-index: 9999;
            transition: background 0.3s;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        .header-container {
            max-width: 1400px;
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0 50px;
        }

        .logo {
            font-size: 20px;
            font-weight: 600;
            color: var(--color-beige);
            text-decoration: none;
            letter-spacing: 3px;
            text-transform: uppercase;
        }

        .nav-menu {
            display: flex;
            gap: 40px;
            list-style: none;
        }

        .nav-menu a {
            color: var(--color-beige);
            text-decoration: none;
            font-size: 13px;
            transition: color 0.3s;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 400;
        }

        .nav-menu a:hover {
            color: var(--color-orange);
        }

        /* Hero Section */
        .hero {
            height: 100vh;
            position: relative;
            display: flex;
            align-items: center;
            justify-content: center;
            background: linear-gradient(135deg, rgba(26, 26, 26, 0.85) 0%, rgba(42, 42, 42, 0.85) 100%), url('../images/bytes.png');
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
            overflow: hidden;
        }

        .hero-content {
            position: relative;
            text-align: center;
            color: var(--color-beige);
            z-index: 2;
            padding: 0 20px;
        }

        .hero-title {
            font-size: 72px;
            font-weight: 300;
            margin-bottom: 20px;
            letter-spacing: 6px;
            text-transform: uppercase;
            color: var(--color-dark-beige);
        }

        .hero-subtitle {
            font-size: 20px;
            font-weight: 300;
            max-width: 900px;
            margin: 0 auto;
            line-height: 1.6;
            color: var(--color-dark-beige);
        }

        .scroll-arrow {
            position: absolute;
            bottom: 50px;
            left: 50%;
            transform: translateX(-50%);
            cursor: pointer;
            z-index: 10;
        }

        .scroll-arrow svg {
            width: 40px;
            height: 40px;
            animation: bounceArrow 2s infinite;
        }

        @keyframes bounceArrow {
            0%, 20%, 50%, 80%, 100% {
                transform: translateY(0);
            }
            40% {
                transform: translateY(-15px);
            }
            60% {
                transform: translateY(-8px);
            }
        }

        /* Intro Section */
        .intro-section {
            padding: 100px 50px;
            background: var(--color-white);
        }

        .intro-container {
            max-width: 1400px;
            margin: 0 auto;
        }

        .intro-text {
            font-size: 18px;
            line-height: 1.9;
            color: var(--color-text-light);
            text-align: center;
            max-width: 1000px;
            margin: 0 auto;
        }

        .intro-text strong {
            color: var(--color-orange);
            font-weight: 600;
        }

        /* Highlight Box */
        .highlight-box {
            background: linear-gradient(135deg, #fff5e6 0%, #ffe8cc 100%);
            padding: 30px;
            border-radius: 8px;
            border-left: 4px solid var(--color-orange);
            margin: 30px 0;
        }

        .highlight-box p {
            margin-bottom: 0;
            color: var(--color-text-dark);
            font-weight: 500;
        }

        /* Methodology Section */
        .methodology-section {
            padding: 0;
            background: var(--color-beige);
            margin-bottom: 0;
        }

        .methodology-section:last-of-type .methodology-text-col {
            border-bottom: none;
        }

        .methodology-container {
            max-width: 1400px;
            margin: 0 auto;
            display: grid;
            grid-template-columns: 1fr 2fr;
            gap: 0;
        }

        .methodology-title-box {
            background: #2a2a2a;
            padding: 120px 60px 80px 60px;
            display: flex;
            flex-direction: column;
            justify-content: flex-start;
            position: sticky;
            top: 60px;
            height: 100vh;
            align-self: flex-start;
        }

        .methodology-number {
            font-size: 80px;
            font-weight: 700;
            color: var(--color-orange);
            line-height: 1;
            margin-bottom: 20px;
        }

        .methodology-title {
            font-size: 32px;
            color: var(--color-beige);
            text-transform: uppercase;
            letter-spacing: 4px;
            line-height: 1.2;
            font-weight: 300;
        }

        .methodology-text-col {
            padding: 80px 80px;
            font-size: 15px;
            line-height: 1.9;
            color: var(--color-text-light);
            background: var(--color-white);
            border-bottom: 1px solid rgba(26, 26, 26, 0.15);
            text-align: justify;
        }

        .methodology-text-col h3 {
            font-size: 20px;
            color: var(--color-black);
            margin-bottom: 20px;
            margin-top: 35px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 2px;
        }

        .methodology-text-col h3:first-child {
            margin-top: 0;
        }

        .methodology-text-col h4 {
            font-size: 16px;
            color: var(--color-orange);
            margin-bottom: 12px;
            margin-top: 25px;
            font-weight: 600;
        }

        .methodology-text-col p {
            margin-bottom: 15px;
        }

        .methodology-text-col ul {
            margin: 15px 0 15px 25px;
            padding: 0;
        }

        .methodology-text-col li {
            margin-bottom: 10px;
            line-height: 1.8;
        }

        .methodology-text-col strong {
            color: var(--color-orange);
            font-weight: 600;
        }

        .methodology-text-col code {
    background: var(--color-beige);
    padding: 2px 6px;
    border-radius: 3px;
    font-family: 'Courier New', monospace;
    font-size: 14px;
    color: var(--color-black);
    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2); /* ombra scura leggera */
}


        .methodology-text-col .requirements-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 25px;
        }

        .methodology-text-col .requirement-card {
            background: var(--color-beige);
            padding: 30px;
            border-radius: 8px;
            border-left: 4px solid var(--color-orange);
            transition: all 0.3s ease;
        }

        .methodology-text-col .requirement-card:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        }

        .methodology-text-col .requirement-number {
            font-size: 42px;
            font-weight: 700;
            color: var(--color-orange);
            line-height: 1;
            margin-bottom: 12px;
        }

        .methodology-text-col .requirement-title {
            font-size: 16px;
            color: var(--color-black);
            margin-bottom: 12px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .methodology-text-col .requirement-description {
            font-size: 13px;
            line-height: 1.7;
            color: var(--color-text-light);
        }

        /* Responsive Design per Methodology */
        @media (max-width: 1200px) {
            .methodology-container {
                grid-template-columns: 1fr;
            }

            .methodology-title-box {
                position: relative;
                height: auto;
            }

            .methodology-text-col {
                border-bottom: 1px solid rgba(26, 26, 26, 0.15);
                border-top: 1px solid rgba(26, 26, 26, 0.15);
            }
        }

        @media (max-width: 768px) {
            .hero {
                height: 100vh;
            }

            .hero-title {
                font-size: 48px;
                letter-spacing: 4px;
            }

            .hero-subtitle {
                font-size: 16px;
            }

            .scroll-arrow svg {
                width: 32px;
                height: 32px;
            }

            .methodology-number {
                font-size: 60px;
            }

            .methodology-title {
                font-size: 28px;
                letter-spacing: 3px;
            }

            .methodology-text-col {
                padding: 60px 40px;
            }
        }
</style>

<!-- Hero Section -->
<section class="hero">
    <div class="hero-content">
        <h1 class="hero-title">Methodology</h1>
        <p class="hero-subtitle">A four-phase approach to modeling, managing, and publishing born-digital archival materials through semantic web technologies</p>
    </div>
    <div class="scroll-arrow">
        <svg viewBox="0 0 24 24" fill="none" stroke="#E86A33" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <polyline points="6 9 12 15 18 9"></polyline>
        </svg>
    </div>
</section>

<!-- Phase 1 -->
<section class="methodology-section">
    <div class="methodology-container">
        <div class="methodology-title-box">
            <div class="methodology-number">01</div>
            <h2 class="methodology-title">Data Analysis<br>& Requirements</h2>
        </div>
        <div class="methodology-text-col">
            
            <h3>The Evangelisti Dataset</h3>
   
            <p  style="text-align: justify"> The born-digital partition of Valerio Evangelisti's Archive documents the author's digital activity from the early 1990s through 2022. As a pioneer in computer adoption since the 1980s, Evangelisti consistently experimented with new technologies, integrating them into his creative and documentary practices.</p>

            <p>The collection analyzed comprises:</p>
            <ul>
                <li><strong>Desktop computer hard drive</strong>: complete contents documenting primary production environment.</li>
                <li><strong>External hard drive</strong>: backup and supplementary material.</li>
                <li><strong>93 floppy disks</strong>: early digital materials (out of 389 total in the collection).</li>
            </ul>

            <p style="text-align: justify">This material diversity – ranging from word processing documents and research notes to email archives, multimedia files, and system backups – exemplifies the representational challenges that contemporary born-digital archives must address. The stratification of formats, software environments, and organizational logics present in the Evangelisti materials directly informed the articulation of the modeling requirements.</p>

            <h3 style="margin-top: 50px; margin-bottom: 30px; text-align: center;">Five Modeling Requirements</h3>
            <p style="text-align: justify; margin-bottom: 30px; color: var(--color-text-light);"> The preliminary research phase involved phenomenological analysis of born-digital authorial materials and identification of specific challenges in their representation. Through the convergence of state-of-the-art review, material analysis, and methodological reflection, five fundamental requirements were identified for modeling, considering their identity, structure, provenance, and contexts.</p>


            <div class="requirements-grid" style="margin-bottom: 30px;">
                <div class="requirement-card">
                    <div class="requirement-number">01</div>
                    <h3 class="requirement-title">File Representation</h3>
                    <p class="requirement-description">The model must enable explicit representation of a file's nature, distinguishing between physical, logical, and content dimensions, supporting typological diversity without privileging or excluding specific formats.</p>
                </div>
                <div class="requirement-card">
                    <div class="requirement-number">02</div>
                    <h3 class="requirement-title">Material Integrity</h3>
                    <p class="requirement-description">The model must support the representation of hash codes and the algorithms used to calculate them (MD5, SHA-1, SHA-256, SHA-512), as identifying elements of the document and its integrity over time.</p>
                </div>
                <div class="requirement-card">
                    <div class="requirement-number">03</div>
                    <h3 class="requirement-title">Native Metadata</h3>
                    <p class="requirement-description">The model must ensure systematic integration of native metadata, documenting their value and provenance, without a priori constraints on the types or granularity of information collected.</p>
                </div>
                <div class="requirement-card">
                    <div class="requirement-number">04</div>
                    <h3 class="requirement-title">Provenance</h3>
                    <p class="requirement-description">The model must support representation of technical, procedural, and interpretive provenance, documenting the history and transformations of digital documents and their related metadata.</p>
                </div>
                <div class="requirement-card">
                    <div class="requirement-number">05</div>
                    <h3 class="requirement-title">Contexts</h3>
                    <p class="requirement-description">The model must enable the representation of multiple contexts, allowing documents to be connected to the manifold relationships, vertical and horizontal, that enrich their meaning, ensuring articulated and contextualized understanding.</p>
                </div>
            </div>

        </div>
    </div>
</section>

<!-- Phase 2 -->
<section class="methodology-section">
    <div class="methodology-container">
        <div class="methodology-title-box">
            <div class="methodology-number">02</div>
            <h2 class="methodology-title">Ontological<br>Model: BoDi</h2>
        </div>
        <div class="methodology-text-col">
            <p>In response to the identified requirements, <strong>
                <a href="http://w3id.org/bodi#" target="_blank" rel="noopener noreferrer" 
                   style="color: var(--color-orange); text-decoration: underline;">
                   BoDi (Born-Digital Ontology)
                </a>
              </strong> was developed as a specialized extension of <strong>
                <a href="https://www.ica.org/standards/RiC/RiC-O_1-1.html" target="_blank" rel="noopener noreferrer" 
                   style="color: var(--color-orange); text-decoration: underline;">
                   Records in Contexts - Ontology (RiC-O)
                </a>
              </strong> dedicated to representing born-digital authorial materials.</p>
        
            <h3>Choice of RiC-O as Base Framework</h3>
            <p>RiC-O was selected as the reference framework for its capacity to represent complex, multidirectional networks of relationships among archival entities, agents, and contexts, reflecting the stratified and interconnected nature of contemporary documentation. RiC-O is progressively establishing itself as a new international reference standard, developed by the <strong><a href="https://www.ica.org/" target="_blank" rel="noopener noreferrer" 
            style="color: var(--color-orange); text-decoration: underline;">International Council on Archives (ICA)</a></strong> through an extensive and participatory process. ICA's <strong><a href="https://www.ica.org/ica-network/expert-groups/egad/" target="_blank" rel="noopener noreferrer" 
            style="color: var(--color-orange); text-decoration: underline;">Expert Group on Archival Description (EGAD)</a></strong> documentation recognizes that RiC is indeed designed with the expectation that it may be extended using cross-domain ontologies specifically addressing technical data needed for the management of instantiations.</p>

        
            <h3>Model Architecture</h3>
            <p>BoDi selectively integrates classes and properties from established ontologies:</p>
            <ul>
                <li><strong>
                    <a href="https://www.ica.org/standards/RiC/RiC-O_1-1.html" target="_blank" rel="noopener noreferrer" 
                       style="color: var(--color-orange); text-decoration: underline;">
                       RiC-O
                    </a>
                </strong>: utilized in its entirety as reference framework</li>
                
                <li><strong>
                    <a href="https://id.loc.gov/ontologies/premis-3-0-0.html" target="_blank" rel="noopener noreferrer" 
                       style="color: var(--color-orange); text-decoration: underline;">
                       PREMIS
                    </a>
                </strong>: for preservation metadata and integrity</li>
                
                <li><strong>
                    <a href="https://www.w3.org/TR/prov-o/" target="_blank" rel="noopener noreferrer" 
                       style="color: var(--color-orange); text-decoration: underline;">
                       PROV-O
                    </a>
                </strong>: for procedural provenance</li>
                
                <li><strong>
                    <a href="https://cidoc-crm.org//extensions/lrmoo/html/LRMoo_v1.0.html" target="_blank" rel="noopener noreferrer" 
                       style="color: var(--color-orange); text-decoration: underline;">
                       LRMoo
                    </a>
                </strong>: for integration with the bibliographic domain</li>
            </ul>
            
            <p>These are complemented by classes and properties developed ad hoc to address specific needs of born-digital authorial materials not covered by existing models.</p>

            <div style="margin: 40px 0; text-align: center;">
                <img src="../images/bodi-class-view.png" alt="BoDi Ontology Class Diagram" style="max-width: 100%; height: auto; border: 1px solid #e0e0e0; border-radius: 4px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
                <p style="margin-top: 15px; font-size: 14px; color: var(--color-text-light); font-style: italic;">BoDi ontology class hierarchy showing extensions to RiC-O (blue), integration with PREMIS (green), PROV-O (purple), and LRMoo (red)</p>
            </div>

            <h3>Modeling Requirement 1: File and Folder Representation</h3>
            <h4>Content Level</h4>
            <p>Modeled through <code>rico:RecordResource</code> and its specializations (<code>rico:Record</code>, <code>rico:RecordSet</code>, <code>rico:RecordPart</code>).</p>
            
            <h4>Logical Level</h4>
            <p>Represented by <code>rico:Instantiation</code>, which identifies the file as a logical entity distinct from content, correlated via <code>rico:isOrWasInstantiationOf</code> and <code>rico:hasOrHasInstantiation</code>.</p>
            <p>BoDi enriches <code>rico:Instantiation</code> with specific properties:</p>
            <ul>
                <li><code>bodi:hierarchyDepth</code>: measures file depth in folder hierarchy</li>
                <li><code>prov:atLocation</code>: documents the file path through <code>prov:Location</code></li>
                <li><code>bodi:hasTechnicalDescriptionOf</code>/<code>bodi:isTechnicalDescriptionOf</code>: link technical descriptions with types distinguishing human and AI-generated productions</li>
            </ul>

            <h4>Physical Level</h4>
            <p>Expressed by the <code>bodi:FileClusterPosition</code> class, which describes the physical allocation of bits on the medium, correlated to the logical level via <code>rico:hasFileClusterPosition</code> and <code>rico:isFileClusterPositionOf</code>.</p>

            <div class="highlight-box">
                <p><strong>Example from the Evangelisti Archive:</strong> The file "01 - La montagna dei pirati.rtf" exemplifies this tripartite stratification. At the <em>content level</em>, it represents the intellectual work – a chapter from Evangelisti's pirate cycle – modeled as a <code>rico:Record</code> with its title and dates. At the <em>logical level</em>, a <code>rico:Instantiation</code> captures its existence as an RTF file located at <code>bodi:hierarchyDepth</code> 2 within the folder location <code>prov:Location</code> ("/Documents/Cartagena/01 - La montagna dei pirati.rtf"). At the <em>physical level</em>, while BoDi includes the <code>bodi:FileClusterPosition</code> class with <code>bodi:startSector</code> and <code>bodi:endSector</code> properties for minimal forensic representation, this dimension was not pursued in the present research, whose focus is primarily on the analysis and modeling of the logical and content levels. This multi-layered representation enables queries spanning from "all works by Evangelisti" to "all files within specific folder structures" without conflating these distinct dimensions.</p>
            </div>

            <h3>Modeling Requirement 2: Integrity and Hash</h3>
            <p>Integrity is modeled through integration of the <code>premis:Fixity</code> class, correlated to <code>rico:Instantiation</code> via <code>bodi:hasHashCode</code> and <code>bodi:isHashCodeOf</code>. The symmetric property <code>bodi:hasSameHashCodeAs</code> enables explicit documentation of relationships between instantiations sharing the same hash value, supporting automatic duplicate identification and migration operation verification.</p>

            <div class="highlight-box">
                <p><strong>Example from the Evangelisti Archive:</strong> The file "01 - La montagna dei pirati.rtf" has a SHA-256 hash value of "61ba86a421faabf85480bd9d245a116804fd245c01393b17128b8d7d90f59ca1", represented as a <code>premis:Fixity</code> instance linked to the <code>rico:Instantiation</code> via <code>bodi:hasHashCode</code>. The calculation was documented through a <code>rico:Activity</code> performed on August 6, 2025 (modeled as <code>rico:Date</code>) by a <code>bodi:Software</code> representing the SHA-256 algorithm. This hash value enables verification of file integrity over time and across different storage locations.</p>
            </div>

            <h3>Modeling Requirement 3: Native Metadata</h3>
            <p>BoDi proposes a flexible and agnostic approach through:</p>
            <ul>
                <li><code>bodi:TechnicalMetadata</code>: linked to <code>rico:Instantiation</code> via <code>bodi:hasTechnicalMetadata</code>, represents metadata value through <code>rdf:value</code></li>
                <li><code>bodi:TechnicalMetadataType</code>: represents metadata type (e.g., FileSize, Software, cp:revision)</li>
                <li><code>bodi:TechnicalMetadataTypeSet</code>: enables grouping of different types according to functional criteria</li>
            </ul>
            <p>The modeling preserves values and types in the exact form retrieved by the extraction tool, without normalization. Extraction is modeled as <code>rico:Activity</code>, permitting coexistence of metadata from different extractions as separate instances.</p>

            <div class="highlight-box">
                <p><strong>Example from the Evangelisti Archive:</strong> From "01 - La montagna dei pirati.rtf", Apache Tika extracted numerous native metadata including the revision count (79 revisions, labeled "RevisionNumber") and file size (74 KB, labeled "FileSize"). Additional metadata included creation date (January 21, 2012), modification date (September 8, 2012), author (Valerio Evangelisti), word count (1643 words), and page count (5 pages). Each metadata value exists as a distinct <code>bodi:TechnicalMetadata</code> instance – connected to the <code>rico:Instantiation</code> via <code>bodi:hasTechnicalMetadata</code> – storing its value through <code>rdf:value</code> and linked to its corresponding <code>bodi:TechnicalMetadataType</code> (e.g., "RevisionNumber", "FileSize")</p>
            </div>

            <h3>Modeling Requirement 4: Provenance</h3>
            <p>BoDi articulates provenance through three dimensions:</p>

            <h4>Custodial History</h4>
            <p>Realized through PREMIS classes <code>premis:StorageMedium</code> and <code>premis:StorageLocation</code>, connected via the <code>premis:medium</code> object property. The <code>premis:StorageMedium</code> class represents the physical nature of the storage medium (e.g., hard disk, SSD, magnetic tape), while <code>premis:StorageLocation</code> documents the physical or logical location where materials are preserved. BoDi introduces the symmetric properties <code>bodi:hasStorageLocation</code> and <code>bodi:isStorageLocationOf</code> to connect <code>rico:Instantiation</code> to <code>premis:StorageLocation</code>, as domain and range constraints prevent direct reuse of the <code>premis:storedAt</code> property. The chain of custody is documented through <code>rico:DerivationRelation</code>, which links two <code>rico:Instantiation</code> instances where one (the target) derives from another (the source) via <code>rico:relationHasSource</code> and <code>rico:relationHasTarget</code> properties. By associating each root-directory <code>rico:Instantiation</code> with its corresponding <code>premis:StorageLocation</code> and <code>premis:StorageMedium</code>, it becomes possible to document the different preservation environments traversed by the materials and the modes of derivation from one environment to another.</p>

            <div class="highlight-box">
                <p><strong>Example from the Evangelisti Archive:</strong> The external hard drive materials underwent three documented migrations, each represented as distinct <code>rico:Instantiation</code> instances linked through <code>rico:DerivationRelation</code>. The original instantiation was connected via <code>bodi:hasStorageLocation</code> to a <code>premis:StorageLocation</code> representing the Associazione Valerio Evangelisti headquarters, which in turn was linked via <code>premis:medium</code> to a <code>premis:StorageMedium</code> describing the Western Digital My Book 2TB USB 3.0 drive. A first <code>rico:DerivationRelation</code> documented the migration to a derived instantiation stored on a Samsung Portable SSD T7 1TB in Cabinet 1 at ADLab (University of Bologna, Via Zamboni 32). A second <code>rico:DerivationRelation</code> tracked the subsequent migration to the final instantiation on a Network Attached Storage (Ext4) in ADLab's Server Room. Each derivation relationship uses <code>rico:relationHasSource</code> and <code>rico:relationHasTarget</code> properties to explicitly document the source-to-target lineage, enabling researchers to verify the materials' custodial history and assess any potential implications of hardware changes on file integrity.</p>
            </div>

            <h4>Agency</h4>
            <p>In the digital context, the principle of provenance extends beyond human authorship to include forms of agency exercised by automated systems and hybrid human-machine processes. BoDi extends the provenance principle by articulating three levels of responsibility:</p>

            <p><strong>Human agency:</strong> RiC-O provides an articulated system through the <code>rico:Person</code> class and the <code>rico:hasOrganicOrFunctionalProvenance</code> super-property, which connects <code>rico:RecordResource</code> or <code>rico:Instantiation</code> to a <code>rico:Agent</code> that creates, accumulates, receives, or sends it. Its sub-properties specify traditional archival roles: <code>rico:hasAuthor</code>, <code>rico:hasCreator</code>, <code>rico:hasAccumulator</code>, <code>rico:hasSender</code>, <code>rico:hasReceiver</code>, <code>rico:hasAddressee</code>, <code>rico:hasCollector</code>. BoDi introduces <code>bodi:generatedBy</code> and its inverse <code>bodi:hasGenerated</code> (sub-properties of <code>rico:isRelatedTo</code>) to address specific digital provenance needs. While RiC-O sub-properties have domain limited to <code>rico:RecordResource</code> and <code>rico:Instantiation</code>, <code>bodi:generatedBy</code> has domain <code>owl:Thing</code>, enabling documentation of generation for entities that are not necessarily archival but require traceability – such as metadata extraction outputs, hash code generation, or curatorial descriptions and annotations.</p>

            <p><strong>Algorithmic agency:</strong> Since <code>rico:Mechanism</code> is defined as a subclass of <code>rico:Agent</code>, properties with range <code>rico:Agent</code> can technically include mechanisms. However, the digital ecosystem requires greater articulation, for which BoDi introduces three subclasses of <code>rico:Mechanism</code>:</p>

            <ul>
                <li><code>bodi:Software</code> (subclass of both <code>premis:SoftwareAgent</code> and <code>rico:Mechanism</code>): represents programs or applications with specific functionalities</li>
                <li><code>bodi:Algorithm</code>: represents computational procedures, formulas, or rule sets designed to perform specific tasks (e.g., cryptographic algorithms like SHA-256 for hash calculation)</li>
                <li><code>bodi:SoftwareComponent</code>: represents modular, reusable parts of software systems that provide specific functionalities and can be combined with other components (e.g., specialized parsers). Components are connected to their reference software through <code>bodi:hasSoftwareComponent</code> and <code>bodi:isSoftwareComponentOf</code></li>
            </ul>

            <p>BoDi further enriches this framework through <code>bodi:SoftwareStack</code>, a subclass of <code>rico:Agent</code> but disjoint from <code>rico:Mechanism</code>, which models aggregations of <code>rico:Mechanism</code> instances collectively executing a <code>rico:Activity</code>. A software stack is composed of elements connected via <code>bodi:hasStackElement</code> and its inverse <code>bodi:isStackElementOf</code> (sub-properties of <code>rico:hasOrHadPart</code> and <code>rico:isOrWasPartOf</code>). The data property <code>bodi:hasDocumentation</code> (domain <code>rico:Thing</code>, range <code>xsd:anyURI</code>) provides URI references to technical specifications, manuals, or official documentation, constituting an essential bridge between ontological instantiation and external technical knowledge.</p>
                        <p><strong>Hybrid agency:</strong> BoDi introduces specific ways to document human governance over digital processes. The object properties <code>bodi:isOrWasSupervisorOf</code> (sub-property of <code>rico:hasOrHadAuthorityOver</code>) and its inverse <code>bodi:hasOrHadSupervisor</code> (sub-property of <code>rico:isOrWasUnderAuthorityOf</code>) connect a <code>rico:Agent</code> (typically a <code>rico:Person</code>) to a <code>rico:Activity</code> performed by a <code>rico:Mechanism</code> or <code>bodi:SoftwareStack</code>, documenting supervisory responsibility. Supervision represents a form of agency exercised through definition of operational parameters, validation of results, and exception management, rather than direct content intervention. For AI-generated content subsequently revised, <code>bodi:hasRevisioned</code> and <code>bodi:revisedBy</code> explicitly connect a <code>rico:Agent</code> to an automatically produced <code>bodi:TechnicalDescription</code> validated by human intervention. Two data properties document quality and reliability: <code>bodi:confidenceScore</code> expresses a numerical value between 0 and 10 indicating the reliability level of generated content, supporting quality assessment workflows and enabling prioritization of human review on low-confidence outputs; <code>bodi:hasHumanValidation</code> indicates whether AI-generated text has been reviewed, verified, or validated by human experts, documenting control intervention and any integration performed.</p>
            <h4>Processes</h4>
                <p>Every significant operation performed on digital materials is modeled as <code>rico:Activity</code>, documenting the executive history of operations. Hash calculation is represented as a <code>rico:Activity</code> that connects the generated <code>premis:Fixity</code> instance, the employed algorithm (e.g., SHA-256), and the execution date. Similarly, native metadata extraction is documented as a <code>rico:Activity</code> specifying which software tool or set of tools, with which configuration, and at which specific moment produced the extraction of each metadata value. Metadata values from different extractions, performed at different times or through alternative tools (e.g., Apache Tika or ExifTool), coexist in the graph as separate instances of <code>bodi:TechnicalMetadata</code> and <code>bodi:TechnicalMetadataType</code>, each connected to its own extraction activity and related <code>rico:Instantiation</code>. This approach preserves complete traceability of extraction operations, supporting comparative analyses and quality verification of extracted data.</p>

                <p>For simpler or consolidated processes, the <code>bodi:generatedBy</code> property offers a direct shortcut that bypasses explicit Activity modeling, simplifying representation when processual detail is not deemed necessary. BoDi introduces the <code>bodi:Exception</code> to represent error conditions, unexpected events, or anomalous situations occurring during process execution. The data property <code>bodi:exceptionMessage</code> contains the error message or description associated with the exception, essential information for logging, debugging, and understanding failures in automated workflows.</p>
                <p>The data property <code>bodi:redactedInformation</code> signals data anonymization interventions for publication purposes, documenting modifications made for privacy or security reasons and rendering transparent curatorial choices that resulted in omission or redaction of sensitive information.</p>

                <div class="highlight-box">
                    <p><strong>Example from the Evangelisti Archive:</strong> The metadata extraction process for "01 - La montagna dei pirati.rtf" exemplifies comprehensive provenance documentation. The <code>rico:Activity</code> of extraction was performed by a <code>bodi:SoftwareStack</code> composed of Apache Tika and specialized parsers (each modeled as <code>bodi:Software</code> or <code>bodi:SoftwareComponent</code> connected via <code>bodi:hasStackElement</code>), with archivist Lucia Giagnolini exercising governance through the <code>bodi:isOrWasSupervisorOf</code> relationship. Each extracted metadata value – such as revision count (79 revisions, labeled "RevisionNumber") and file size (74 KB, labeled "FileSize") – exists as a distinct <code>bodi:TechnicalMetadata</code> instance linked to its <code>bodi:TechnicalMetadataType</code> and connected to the generating activity via <code>bodi:generatedBy</code>. The activity itself is timestamped with a <code>rico:Date</code> (August 6, 2025). When an AI-generated technical description was produced for the file, the <code>bodi:hasRevisioned</code> property documents which descriptions underwent human validation, with <code>bodi:confidenceScore</code> of AI output values enabling prioritization of review efforts and accountability of the information. Privacy-sensitive materials are marked with <code>bodi:redactedInformation</code>, transparently documenting curatorial decisions to redact information while preserving the structural integrity of the archive and non-sensitive metadata for quantitative analysis.</p>
                </div>

            <h3>Modeling Requirement 5: Contexts</h3>
            <h4>Vertical Dimension</h4>
            <p>BoDi fully adopts the RiC-O framework, representing hierarchy through <code>rico:Record</code> (document) and <code>rico:RecordSet</code> (aggregation of documents), linked by <code>rico:includesOrIncluded</code> and <code>rico:isOrWasIncludedIn</code>, which express the vertical inclusion relationship between archival description levels. RiC-O's design choice not to prescribe a fixed number of descriptive levels or predefined nomenclature (fonds, series, sub-series, files, etc.) proves particularly appropriate for born-digital authorial materials. Digital materials often present organizations that do not conform to traditional categorizations: a folder structure may reflect personal work logics, thematic aggregations, or hybrid criteria mixing multiple organizational dimensions and depths. RiC-O's agnosticism regarding canonical descriptive levels enables representation of these articulations without interpretative forcing, documenting the hierarchy as it manifests in the materials rather than normalizing it according to predetermined schemas.</p>

            <p>This flexibility does not preclude the possibility of typing aggregations when necessary. The <code>rico:RecordSetType</code> class permits qualification of a <code>rico:RecordSet</code>'s nature, specifying whether it is a fonds, series, thematic dossier, or any other form of aggregation relevant to the specific context. This typing can be applied selectively, only where it provides effective descriptive value. The <code>rico:RecordSet</code> class represents a flexible aggregating entity capable of accommodating and describing sets of materials according to criteria different from canonical ones. In the context of born-digital authorial materials, beyond mirroring the original file system structure where folders and subfolders correspond to nested <code>rico:RecordSet</code> instances, this class enables construction of alternative aggregations based on thematic, typological, chronological, and curatorial criteria, also derived from knowledge graph querying. Thus, <code>rico:RecordResource</code> becomes a convergence node representing the plurality of possible perspectives on digital materials, without being constrained to a single hierarchical or descriptive structure. This multiplicity does not generate problematic conflicts or redundancies: each <code>rico:RecordSet</code> represents a legitimate interpretative perspective on the materials, and different aggregations can coexist in the graph, enriching its navigability.</p>

            <h4>Horizontal Dimension</h4>
            <p>While the vertical dimension documents the hierarchical stratification of materials, the horizontal dimension opens toward multiple possibilities, largely already supported by RiC-O's granularity and variety of classes and properties. In the context of literary archives, this dimension assumes particular relevance through integration with the bibliographic domain, realized in BoDi through adoption of LRMoo (IFLA Library Reference Model - Object-Oriented). The central class of this integration is <code>lrmoo:F1_Work</code>, which represents a work in the sense of intellectual or artistic creation distinct from its material manifestations. In the context of authorial archives, <code>lrmoo:F1_Work</code> enables representation of the literary work as a conceptual entity – for example, the novel Cartagena understood as intellectual creation – distinguishing it from its various manifestations such as manuscripts, drafts, editions, and translations. An instance of <code>lrmoo:F1_Work</code> can be connected to a <code>rico:RecordResource</code> through the object property <code>rico:isOrWasSubjectOf</code> or, alternatively, through the more general <code>rico:isRelatedTo</code>, thus making explicit the link between the work and the materials that document it.</p>

            <p>This integration enables transversal navigation paths that significantly amplify interpretative contexts. A researcher interested in the work "Cartagena" can identify in the graph not only the published novel, but the entire documentary ecosystem surrounding it: preparatory manuscripts, editorial correspondence, work notes, intermediate versions, translations, reviews. LRMoo further permits modeling of this aspect through the <code>lrmoo:F2_Expression</code> class, which represents the intellectual or artistic realization of a work in a specific form (e.g., an edition, translation, adaptation, revision). Through these classes it becomes possible to document the complex genealogies of literary works, their derivations, transformations, and reworkings.</p>

            <div class="highlight-box">
                <p><strong>Example from the Evangelisti Archive:</strong> The "01 - La montagna dei pirati.rtf" file demonstrates both contextual dimensions. <em>Vertically</em>, the hierarchy is articulated on two parallel levels: at the <em>logical level</em>, the file instantiation (<code>rico:Instantiation</code>) is connected to the "Cartagena" folder instantiation (also a <code>rico:Instantiation</code>) through <code>rico:isOrWasPartOf</code> and <code>rico:hasOrHadPart</code> relationships, which in turn is part of the Documents directory structure on the external hard drive; at the <em>content level</em>, the record representing this chapter (<code>rico:Record</code>) is included within the broader "Cartagena" recordset (<code>rico:RecordSet</code>) through <code>rico:isOrWasIncludedIn</code> and <code>rico:includesOrIncluded</code> relationships. <em>Horizontally</em>, the record connects to two literary works (both modeled as <code>lrmoo:F1_Work</code>) via <code>rico:hasOrHadSubject</code>: the specific novel "Cartagena" and the broader "Ciclo dei pirati" (Pirate Cycle). This dual connection enables discovery of all archival materials related either to this specific novel or to the entire pirate cycle regardless of their hierarchical location – other chapters from different novels in the cycle, research notes, correspondence with publishers, historical documentation, translations, reviews. A researcher interested in Cartagena can thus navigate from the published work to find drafts, notes, and revisions scattered across different folders and storage media, or alternatively explore the entire pirate cycle to understand the broader creative project, reconstructing the creative genealogy of the text through semantic relationships rather than relying solely on file system organization. This integration creates an ecosystem where conceptual works serve as focal points for aggregating diverse documentary manifestations that would otherwise remain dispersed across the archival hierarchy.</p>
            </div>
            <h3>Data Population</h3>
            <p>The BoDi model was populated with data from the born-digital materials of the Evangelisti Archive through a <strong><a href="https://github.com/LuciaGiagnolini12/FileSystem_to_BoDi" target="_blank rel="noopener noreferrer" 
                style="color: var(--color-orange); text-decoration: underline;">structured Python pipeline</a></strong> that enabled automation of the data generation process. This computational workflow takes as input the folders of the born-digital archive and produces as output an RDF knowledge base conforming to the BoDi model. The workflow is articulated in five operational phases:</p>
                <div style="margin: 40px 0; text-align: center;">
                    <img src="../images/workflow.png" alt="Workflow" style="max-width: 100%; height: auto; border: 1px solid #e0e0e0; border-radius: 4px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
                    <p style="margin-top: 15px; font-size: 14px; color: var(--color-text-light); font-style: italic;">Five-step workflow for transforming born-digital archives into an RDF knowledge base compliant with the BoDi model.</p>
                </div>
            <h4>Phase 1: Systematization of Existing Information</h4>
            <p>This foundational phase produces a formalized representation of the archive's content structure, creating a semantic snapshot. Through ten progressive steps, files and folders are transformed into structured semantic representations. The process begins with protective measures rendering the archive immutable, proceeds through complete hierarchical census and generation of SHA-256 cryptographic fingerprints for each file, and continues with systematic metadata extraction through three specialized tools (Python os library, Apache Tika, ExifTool) ensuring comprehensive coverage of technical characteristics. All captured information undergoes semantic transformation into RDF entities conforming to BoDi specifications, with final integrity checks ensuring no operations have compromised the authenticity of original materials.</p>

            <h4>Phase 2: Rule-Based Validation and Enrichment</h4>
            <p>Operating exclusively in the semantic domain, this phase validates logical coherence of produced graphs and explicates implicit knowledge through controlled inference processes. The validation system implements SPARQL queries verifying structural consistency, metadata presence, and relationship coherence. Following validation, semantic enrichment proceeds through six operations: correlation of files with identical content via hash analysis; alignment of metadata types extracted by different tools; subdivision of metadata into nine functional categories; assignment of document types based on media types; attribution of titles and dates (creation and modification) to entities according to the RiC-O model.</p>

            <h4>Phase 3: Semantic Enrichment Through Specialized Knowledge and Generative Models</h4>
            <p>This phase extends the informational perimeter through integration of specialized knowledge sources and artificial intelligence technologies. The approach implements two enrichment processes: a semi-automatic mapping of Evangelisti's literary works according to the LRMoo model (IFLA Library Reference Model), systematically connecting archival documents to reference works through specialized bibliographic analysis; and an automated system based on LLMs producing synoptic descriptions in natural language derived from extracted metadata analysis.</p>

            <h4>Phase 4: Documentation of Original Contexts</h4>
            <p>This phase reconstructs the original contexts of materials and documents the chain of custody connecting original media to working copies used for analysis. It includes census of different digital environments, reconstruction of their characteristics, and temporal and processual relationships involving them. Minimal descriptive data derived from the census is represented according to the BoDi model, enriching the graph with information on provenance contexts and conservation history of digital documents.</p>

            <h4>Phase 5: Anonymization for Publication</h4>
            <p>The final phase implements selective anonymization strategies preserving the archive's structure and informational content while ensuring protection of sensitive information. The system distinguishes between different types of archival resources, applying differentiated and modifiable logics according to case-specific needs.</p>

            <p>The automated pipeline ensures:</p>
            <ul>
                <li><strong>Consistency</strong> in metadata extraction and representation across the entire collection</li>
                <li><strong>Scalability</strong> for processing large volumes of heterogeneous digital materials</li>
                <li><strong>Reproducibility</strong> of the data generation process for quality control and verification</li>
                <li><strong>Documentation</strong> of all computational processes within the knowledge graph</li>
            </ul>

                    </div>
                </div>
            </section>

<!-- Phase 3 -->
<section class="methodology-section">
    <div class="methodology-container">
        <div class="methodology-title-box">
            <div class="methodology-number">03</div>
            <h2 class="methodology-title">Data Management:<br>Blazegraph</h2>
        </div>
        <div class="methodology-text-col">
            <p>For managing and querying data represented in BoDi, <strong><a href="https://blazegraph.com/" target="_blank rel="noopener noreferrer" 
                style="color: var(--color-orange); text-decoration: underline;">Blazegraph</a></strong> was adopted as the reference triplestore. Blazegraph™ is an ultra high-performance graph database supporting both Blueprints and RDF/SPARQL APIs, capable of handling up to 50 billion edges on a single machine. The platform is in production use by Fortune 500 companies and powers critical applications including the Wikimedia Foundation's Wikidata Query Service. The selection of this technological environment responded to the necessity of identifying a robust, scalable platform capable of enabling publication, exploration, and querying of descriptive data in RDF format, while ensuring separation between data structure and presentation modality.</p>

            <h3>Key Capabilities</h3>
            <ul>
                <li><strong>Efficient storage</strong> of large-scale RDF graphs with proven scalability for billions of triples</li>
                <li><strong>High-performance querying</strong> through complex SPARQL queries with optimized execution</li>
                <li><strong>Native integration</strong> with visualization platforms based on Semantic Web technologies</li>
                <li><strong>Production-grade reliability</strong> demonstrated through widespread adoption in life sciences, precision medicine, and cyber analytics applications</li>
                <li><strong>Open-source architecture</strong> with active community support via GitHub and JIRA issue tracking</li>
            </ul>

            <h3>SPARQL Endpoint</h3>
<p>The <strong><a href="http://evangelisti.dharc.unibo.it/resource/sparql" target="_blank" style="color: var(--color-orange); text-decoration: underline;">SPARQL endpoint</a></strong> enables researchers and advanced users to execute personalized queries on the data, retrieving information according to specific criteria and combinations of parameters not predefined in the graphical interface. This architecture ensures separation between the storage/querying level and the presentation level, permitting multiple access modalities to the same informational base. The endpoint provides direct access to the RDF knowledge graph, supporting both simple property-path queries and complex federated queries for advanced research needs.</p>
        </div>
    </div>
</section>

<!-- Phase 4 -->
<section class="methodology-section">
    <div class="methodology-container">
        <div class="methodology-title-box">
            <div class="methodology-number">04</div>
            <h2 class="methodology-title">Data Presentation:<br>ResearchSpace</h2>
        </div>
        <div class="methodology-text-col">
            <p>For publication, exploration, and data access, <strong><a href="https://researchspace.org/" target="_blank" rel="noopener noreferrer" style="color: var(--color-orange); text-decoration: underline;">ResearchSpace</a></strong> was selected as the platform – an open-source environment for managing and publishing knowledge graphs dedicated to cultural heritage. Developed at the <strong>British Museum</strong> with support from the <strong>Andrew W. Mellon Foundation</strong> and in partnership with <strong><a href="https://metaphacts.com/" target="_blank" rel="noopener noreferrer" style="color: var(--color-orange); text-decoration: underline;">Metaphacts</a></strong>, the platform is currently maintained by <strong><a href="https://kartography.org/" target="_blank" rel="noopener noreferrer" style="color: var(--color-orange); text-decoration: underline;">Kartography CIC</a></strong>, a non-profit social enterprise registered as a Community Interest Company in England and Wales. The platform is actively developed through its <strong><a href="https://github.com/researchspace/researchspace" target="_blank" rel="noopener noreferrer" style="color: var(--color-orange); text-decoration: underline;">public GitHub repository</a></strong>, enabling community participation and collaborative improvement.</p>

            <h3>Platform Architecture</h3>
            <p>ResearchSpace is defined by its developers as a platform designed to "help establish a community of researchers, where their underlying activities are framed by data sharing, active engagement in formal arguments, and semantic publishing." The architecture is based on Semantic Web technologies, utilizing RDF for data representation and SPARQL as query language. The system is structured in integrable and configurable modules (templates), each offering specialized functionalities adaptable to individual project needs.</p>

            <h4>Query-Based Visualization System</h4>
            <p>A fundamental characteristic of ResearchSpace is its <strong>data-driven approach to visualization</strong>. Each template is constructed around one or more SPARQL queries that retrieve data to be displayed, which can be defined and modified according to project objectives. Above this interrogation layer, the template specifies the presentation modalities of the extracted data, enabling extensive customization both functionally – in the logic of visualization and interaction objectives – and graphically.</p>
            
            <p>This architectural approach ensures <strong>complete separation between data structure and presentation modality</strong>. Since data are structured according to a formal semantic model and expressed in RDF, they are not constrained to a single form of representation but can be interrogated and visualized through different modalities depending on cognitive objectives and consultation needs. Through ResearchSpace, the same informational base can generate alternative views (hierarchical, reticular, chronological, thematic, etc.) without requiring duplication or transformation of underlying data, as SPARQL queries determine which portion of the graph and which relationships become visible in each context.</p>
            
            <p>This paradigm offers significant advantages for archival research: researchers can access the same knowledge graph through multiple complementary perspectives, each optimized for specific analytical or exploratory tasks, while maintaining coherence and integrity of the underlying semantic structure.</p>

            <h3>Core Modules</h3>
            <ul>
                <li><strong>Semantic Search and Forms</strong>: Contextual and faceted searches enabling precise data discovery</li>
                <li><strong>Knowledge Patterns</strong>: Reusable ontological schemas for adding, retrieving, and modifying complex relationships between entities</li>
                <li><strong>Knowledge Maps</strong>: Network visualization of connections between actors, places, events, objects, and concepts</li>
                <li><strong>Image Viewer</strong>: Comparison and annotation capabilities for high-resolution images</li>
                <li><strong>Semantic Narratives</strong>: Dynamic combination of text, visualizations, tables, and knowledge maps that update automatically as data evolves</li>
                <li><strong>Timelines and Geographic Maps</strong>: Temporal and spatial data visualization for contextual understanding</li>
            </ul>

            <h3>Implementation for the Evangelisti Archive</h3>
            <p>The project represented the <strong>first implementation of ResearchSpace based on an archival ontology</strong> (BoDi/RiC-O), verifying its compatibility with frameworks different from CIDOC CRM, for which the system was originally designed. This pioneering implementation demonstrated the platform's flexibility in supporting diverse ontological frameworks beyond the cultural heritage domain for which it was initially developed.</p>

            <h4>Semantic Tree Advanced</h4>
            <p>To address the specific needs of the Evangelisti Archive, an extended version of the Semantic Tree module was developed, introducing advanced functionality for large-scale archival navigation:</p>

            <ul>
                <li><strong>Progressive Loading</strong>: Instead of retrieving the entire graph in a single query, only the root and first level are initially displayed. Node expansion activates asynchronous loading of descendants, optimizing processing times and enabling management of large-scale datasets without performance degradation.</li>
                
                <li><strong>Integrated Search</strong>: Operates directly on the tree structure, filtering and reorganizing the hierarchy to highlight pertinent nodes within their archival context. Results remain embedded in the structural view rather than generating separate result lists, preserving contextual relationships.</li>
                
                <li><strong>Reversible and Combinable Filters</strong>: Enable temporary hiding of nodes not satisfying certain conditions (e.g., materials anonymized for privacy), while maintaining possibility of quantitative analysis via direct SPARQL queries against the complete dataset.</li>
                
                <li><strong>Recursive Sorting</strong>: Enables reorganization of visualization according to user-defined criteria (title, date, IRI, number of descendant elements), applied consistently across all hierarchy levels to facilitate different analytical perspectives.</li>
                
                <li><strong>Related Nodes System</strong>: Mouse-over on each node reveals a menu proposing configurable correlation criteria (same creation date, same software, same hash, functional/thematic correlations). Related nodes are automatically highlighted in the view, enabling recognition of transversal connections crossing archival organization and revealing semantic relationships beyond hierarchical structure.</li>
            </ul>

            <h3>Visualization Interface</h3>
            <p>The interface adopts a <strong>two-column layout</strong> that combines hierarchical navigation with detailed information display. The left column presents the <strong>Semantic Tree Advanced</strong> module, while the right column dynamically displays comprehensive metadata for the selected node.</p>

            <h4>Archival Structure Navigation</h4>
            <p>The hierarchical structure identifies at the highest level a general grouping of <strong>Born-Digital Materials</strong>, subdivided into three main media types:</p>
            <ul>
                <li><strong>Primary Hard Drive</strong>: Materials from Evangelisti's main computer</li>
                <li><strong>External Hard Drive</strong>: Contents from the external storage device</li>
                <li><strong>Floppy Disks Collection</strong>: Digitized materials from physical floppy disk media</li>
            </ul>
            <p>Each grouping replicates the original folder and subfolder organization, enabling users to navigate the archive using the familiar file system metaphor. Nodes can be progressively expanded by clicking on the tree structure, triggering asynchronous loading of child elements without performance degradation.</p>

            <h4>Interactive Search and Filtering</h4>
            <p>The interface provides multiple access modalities for exploring the archive:</p>
            <ul>
                <li><strong>Integrated Search</strong>: A search bar enables full-text queries across all archive nodes. Results are highlighted directly within the tree structure, maintaining contextual relationships rather than displaying isolated result lists. The search operates on both Record and RecordSet entities, filtering through node labels to identify relevant materials.</li>
                
                <li><strong>Privacy Filter</strong>: A configurable filter option allows users to hide nodes containing anonymized information while preserving the visibility of parent folders. This feature is enabled by default and can be toggled to reveal the complete archival structure, supporting both privacy-compliant browsing and comprehensive quantitative analysis.</li>
            </ul>

            <h4>Related Nodes Discovery</h4>
            <p>Mouse-over interaction on any node reveals a menu of <strong>related node criteria</strong>, enabling transversal navigation across the hierarchical structure:</p>
            <ul>
                <li><i class="fa fa-copy" style="color: var(--color-orange); margin-right: 8px;"></i><strong>Same Hash</strong>: Identifies all records with identical file hash codes, revealing duplicate files regardless of their location in the archival structure</li>
                <li><i class="fa fa-book" style="color: var(--color-orange); margin-right: 8px;"></i><strong>Same Work</strong>: Locates all materials related to the same intellectual work, excluding broader categories like cycles or trilogies to maintain specificity</li>
                <li><i class="fa fa-calendar" style="color: var(--color-orange); margin-right: 8px;"></i><strong>Same Creation Date</strong>: Highlights all records created on the same date, enabling temporal analysis of authorial production</li>
            </ul>
            <p>Upon selecting a criterion, related nodes are automatically highlighted throughout the tree view, allowing users to recognize semantic connections that transcend the physical archival organization.</p>

            <h4>Detail Panel Display</h4>
            <p>When a node is selected, the right column displays comprehensive metadata organized into multiple sections:</p>

            <p><strong>For Main Groupings</strong> (Primary Hard Drive, External Hard Drive, Floppy Disks Collection):</p>
            <ul>
                <li><strong>General Overview</strong>: Comprehensive content description and contextual information</li>
                <li><strong>Quantitative Information</strong>: Total number of descendant elements within the collection</li>
                <li><strong>Chronological Extremes</strong>: Temporal boundaries spanning the earliest and latest materials</li>
                <li><strong>Archival History</strong>: Complete chain of custody documentation, including all migration events between storage media, with detailed information on methodologies, software tools, processing dates, and curatorial supervision accessible through expandable information boxes</li>
            </ul>

            <p><strong>For Folders and Individual Files</strong>:</p>
            <ul>
                <li><strong>Preview Description</strong>: AI-generated summary providing contextual overview of content, generated via Large Language Model analysis</li>
                
                <li><strong>Integrity Verification</strong>: Complete hash code information with full provenance chain documenting calculation activity, including extraction date, processing time, software tools, and supervisory oversight</li>
                
                <li><strong>Technical Metadata</strong>: Comprehensive extraction organized by category:
                    <ul style="margin-top: 8px;">
                        <li><em>File System Metadata</em>: Filesystem-level information (file name, path, size, dates)</li>
                        <li><em>Document Content Metadata</em>: Content-specific properties extracted from document files</li>
                        <li><em>Image Metadata</em>: Visual content properties including resolution, color space, and embedded EXIF data</li>
                        <li><em>Other Technical Metadata</em>: Additional domain-specific properties</li>
                    </ul>
                </li>
                
                <li><strong>Work References</strong>: Links to Evangelisti's published works when materials are associated with specific literary productions</li>
            </ul>

            <h4>Provenance Transparency</h4>
            <p>Every metadata element in the detail panel includes an <strong>information icon</strong> <i class="fa fa-info-circle" style="color: #17a2b8; margin-left: 4px; margin-right: 4px;"></i> that, when clicked, opens a modal dialog displaying complete provenance information:</p>
            <ul>
                <li><strong>Activity</strong>: Type of curatorial or computational activity performed</li>
                <li><strong>Date</strong>: Precise timestamp of the operation</li>
                <li><strong>Processing Time</strong>: Computational duration for automated processes</li>
                <li><strong>Supervisor</strong>: Human oversight or automated system responsible for the operation</li>
            </ul>
            <p>This granular provenance tracking ensures complete transparency and traceability of all curatorial interventions, supporting scholarly verification and methodological reproducibility.</p>

        </div>
    </div>
</section>